{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data cost time: 0.33654046058654785\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "gc.collect()\n",
    "s = time.time()\n",
    "\n",
    "dfName = ['user_info_format1','train_format1','user_log_format1']\n",
    "\n",
    "# path = \"C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/tmall/data_format1\"\n",
    "path = \"../data_format1\"\n",
    "\n",
    "df1 = pd.read_csv(path+'/%s.csv'%dfName[0],sep=',')\n",
    "# df2 = pd.read_csv(path+'/%s.csv'%dfName[1],sep=',')\n",
    "# df3 = pd.read_csv(path+'/%s.csv'%dfName[2],sep=',')\n",
    "\n",
    "s0 = time.time()\n",
    "print('read data cost time:',s0-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  df: dataframe\n",
    "#  tag: column be search\n",
    "#  L: list of condiction. if not in L then replace to be R\n",
    "#  r: the number be replace\n",
    "#  R: to replace the number which not fit condiction\n",
    "\n",
    "def fillNull(df, tag, R):\n",
    "    df[tag] = df[tag].fillna(R)\n",
    "    df.info()\n",
    "\n",
    "\n",
    "def replaceNum(df, tag, r, R):\n",
    "    df[tag] = df[tag].replace(r, R)\n",
    "\n",
    "\n",
    "def checkCondition(df, tag, L, R):\n",
    "    df[tag] = np.where(~df[tag].isin(L), R, df[tag])\n",
    "\n",
    "\n",
    "def dropNull(df, tag_list):\n",
    "    return df.dropna(subset=tag_list)\n",
    "\n",
    "\n",
    "def dropDup(df, tag):\n",
    "    return df.drop_duplicates(tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean user_info_format1 table cost time: 5.7266762256622314\n",
      "save user_info_format1 table to csv as \"user_info_format1-2.csv\" cost time: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 'user_info_format1'\n",
    "\n",
    "df1=dropNull(df1, ['user_id'])    # drop should be first, that can cut calculate short \n",
    "df1=dropDup(df1, ['user_id'])\n",
    "fillNull(df1,'gender',2)\n",
    "fillNull(df1,'age_range',0)\n",
    "replaceNum(df1,\"age_range\",8,7)\n",
    "checkCondition(df1,'gender',[0,1,2],2)\n",
    "df1.drop_duplicates()\n",
    "\n",
    "s1=time.time()\n",
    "print('clean %s table cost time:'%dfName[0],s1-s0)\n",
    "\n",
    "\n",
    "# export data\n",
    "# df1.to_csv(r'%s-2.csv'%dfName[0],sep=',',index=False,mode='a')\n",
    "s2=time.time()\n",
    "print('save %s table to csv as \"%s-2.csv\" cost time:'%(dfName[0],dfName[0]),s2-s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train_format1'\n",
    "\n",
    "df2=dropNull(df2, ['user_id','merchant_id','label'])\n",
    "df2=dropDup(df2, ['user_id','merchant_id','label'])\n",
    "checkCondition(df2, 'label', [0,1], np.nan)    # if label's content is not 1 or 0 , than put it NaN\n",
    "df2=dropNull(df2, ['label'])    # drop row that we put NaN\n",
    "df2.drop_duplicates()\n",
    "\n",
    "s3=time.time()\n",
    "print('clean %s table cost time:'%dfName[1],s3-s2)\n",
    "\n",
    "\n",
    "# export data\n",
    "# df2.to_csv(r'%s-2.csv'%dfName[1],sep=',',index=False,mode='a')\n",
    "s4=time.time()\n",
    "print('save %s table to csv as \"%s-2.csv\" cost time:'%(dfName[1],dfName[1]),s4-s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save user_log_format1 table to csv as \"user_log_format1-2.csv\" cost time: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 'user_log_format1'\n",
    "\n",
    "df3=dropNull(df3, ['user_id','item_id'])\n",
    "d3=dropDup(df3, ['user_id','item_id','cat_id','seller_id','brand_id','time_stamp','action_type'])\n",
    "replaceNum(df3,\"cat_id\",np.nan,-1)\n",
    "replaceNum(df3,\"seller_id\",np.nan,-1)\n",
    "replaceNum(df3,\"brand_id\",np.nan,-1)\n",
    "replaceNum(df3,\"time_stamp\",np.nan,-1)\n",
    "replaceNum(df3,\"action_type\",np.nan,-1)\n",
    "df3.drop_duplicates()\n",
    "\n",
    "s5=time.time()\n",
    "# print('clean %s table cost time:'%dfName[2],s5-s4)\n",
    "\n",
    "\n",
    "# export data\n",
    "# df3.to_csv(r'%s-2.csv'%dfName[2],sep=',',index=False,mode='a')\n",
    "s6=time.time()\n",
    "print('save %s table to csv as \"%s-2.csv\" cost time:'%(dfName[2],dfName[2]),s6-s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total cost time:',time.time()-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# import csv\n",
    "\n",
    "\n",
    "# with sqlite3.connect(\"TmallDB\") as conn:\n",
    "# #     c = conn.cursor()\n",
    "#     df1.to_sql(dfName[0],if_exists=False)\n",
    "#     df2.to_sql(dfName[1],if_exists=False)\n",
    "#     df3.to_sql(dfName[2],if_exists=False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert \"user_log_format1_2\" to mysql cost time: 2060.9664976596832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nthis is not a good order to write code like this.\\nbecause all the df arre stock in memory.\\nit should write to db after every df cleaned then gc that shit.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import gc\n",
    "\n",
    "s = time.time()\n",
    "(user, pwd, ip, port, db, charset) = ('user01', 'user01', '192.168.31.73', '3306', 'tmall', 'utf8')\n",
    "engine = create_engine(\"mysql+pymysql://%s:%s@%s:%s/%s?charset=%s\"%(user, pwd, ip, port, db, charset)) \n",
    "# engine = create_engine(\"mysql+pymysql://root:password@localhost:3306/tmall?charset=utf8\") \n",
    "\n",
    "# df1.to_sql(name = dfName[0]+'_2', con = engine,if_exists = 'replace', index = False, chunksize = 100000)\n",
    "# s1 = time.time()\n",
    "# print('insert \"%s\" to mysql cost time:'%(dfName[0]+'_2'), s1-s)\n",
    "# df2.to_sql(name = dfName[1]+'_2', con = engine,if_exists = 'replace', index = False, chunksize = 100000)\n",
    "# s2 = time.time()\n",
    "# print('insert \"%s\" to mysql cost time:'%(dfName[1]+'_2'), s2-s1)\n",
    "\n",
    "# del [[df1,df2]]\n",
    "# gc.collect()\n",
    "\n",
    "df3.to_sql(name = dfName[2]+'_2', con = engine,if_exists = 'replace', index = False, chunksize = 50000)\n",
    "s3 = time.time()\n",
    "print('insert \"%s\" to mysql cost time:'%(dfName[2]+'_2'), s3-s)\n",
    "\n",
    "del [[df3]]\n",
    "gc.collect()\n",
    "\n",
    "'''\n",
    "this is not a good order to write code like this.\n",
    "because all the df arre stock in memory.\n",
    "it should write to db after every df cleaned then gc that shit.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert \"user_info_format1_2\" to mysql cost time: 11.630783081054688\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import gc\n",
    "\n",
    "\n",
    "def df_to_mysql(df, df_name, user, pwd, ip, port, db, charset, if_exists = 'replace', index = False, chunksize = 50000):\n",
    "    s = time.time()\n",
    "    engine = create_engine(\"mysql+pymysql://%s:%s@%s:%s/%s?charset=%s\"%(user, pwd, ip, port, db, charset)) \n",
    "\n",
    "    df.to_sql(name =  df_name+'_2', con = engine,if_exists = 'replace', index = False, chunksize = 50000)\n",
    "    s3 = time.time()\n",
    "    print('insert \"%s\" to mysql cost time:'%( df_name+'_2'), time.time()-s)\n",
    "\n",
    "    del [[df]]\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "#     test\n",
    "df_to_mysql(df1, dfName[0], 'user01', 'user01', '192.168.31.73', '3306', 'tmall', 'utf8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
